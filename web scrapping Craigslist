
import requests
from bs4 import BeautifulSoup
from functools import reduce
import pandas as pd

def getHTMLText(url):
    try:
        r = requests.get(url, timeout = 30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return 'Exception!'
    
def nextPage(soup):
    '''
    return: next_page url
    '''    
    url = 'https://sandiego.craigslist.org'
    body = soup.body
    button = body.section.find('span', class_ = 'buttons')
    buttonnext = button.find('a', class_ = 'button next')
    #print(buttonnext)
    url +=  buttonnext['href']
    #url +=  buttonnext.a['href']
    #print(button.a['href'])
    #print(url)
    return url
    
    

def fillItemList(text):
    '''
    param: text
    return: soup, list[list]
    
    
    '''
    soup = BeautifulSoup(text,'html.parser')
    body = soup.body
    for child in body.section.children:
        if child.name == 'form':
            form = child
        
    ct = form.find('div', class_ = 'content')
    item_list = ct.ul
    item_info = []

    for item in item_list.find_all('li'):
    
        item_title = item.p.a.string
        #print(item_title)
        meta = item.p.find('span', class_ = 'result-meta')
        item_price = meta.span.string
        post_date = item.p.find('time')
        item_date = post_date['datetime']
        
        image = 'No' if len(item.a['class']) == 3 else 'Yes'
        name = item_title
        price = item_price
        postDate = item_date
        
        item_info.append([name, price, postDate, image])
        
    return soup, item_info

def outputFile(d):
    '''
    param: d
    type: list[list]
    
    '''
    name, price, date, image = [],[],[],[]
    for i in d:
        name.append(i[0])
        price.append(i[1])
        date.append(i[2])
        image.append(i[3])
    
    dataframe = pd.DataFrame({'Name': name, 'Price': price, 'postDate': date, 'HasImage': image})
    dataframe.to_csv('/Users/kewang/craigslist_item_iphoneX.csv',index = True)

 


if __name__ == '__main__':
    url = 'https://sandiego.craigslist.org/search/sss?query=iphone+x&sort=rel'
          
    r = getHTMLText(url)
    s, d = fillItemList(r)
    try: 
        for i in range(10):
            url = nextPage(s)
            r = getHTMLText(url)
            s_next, d_next = fillItemList(r)
            for i in d_next:
                d.append(i)
                s = s_next
    except:
        pass
        
    outputFile(d)
